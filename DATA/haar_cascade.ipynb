{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rounded_rect(img, bbox, line_color=(255, 255, 255), ellipse_color=(0, 0, 255), line_thickness=2,\n",
    "                      ellipse_thickness=3, radius=15):\n",
    "    \"\"\" Draw a rectangle with rounded corners, allowing separate colors and thicknesses for lines and ellipses. \"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "\n",
    "    # Draw straight lines between corner circles (rectangular part)\n",
    "    cv.line(img, (x1 + radius, y1), (x2 - radius, y1), line_color, line_thickness)\n",
    "    cv.line(img, (x1 + radius, y2), (x2 - radius, y2), line_color, line_thickness)\n",
    "    cv.line(img, (x1, y1 + radius), (x1, y2 - radius), line_color, line_thickness)\n",
    "    cv.line(img, (x2, y1 + radius), (x2, y2 - radius), line_color, line_thickness)\n",
    "\n",
    "    # Draw arcs at the corners (ellipse part)\n",
    "    cv.ellipse(img, (x1 + radius, y1 + radius), (radius, radius), 180, 0, 90, ellipse_color, ellipse_thickness)  # Top-left corner\n",
    "    cv.ellipse(img, (x2 - radius, y1 + radius), (radius, radius), 270, 0, 90, ellipse_color, ellipse_thickness)  # Top-right corner\n",
    "    cv.ellipse(img, (x1 + radius, y2 - radius), (radius, radius), 90, 0, 90, ellipse_color, ellipse_thickness)   # Bottom-left corner\n",
    "    cv.ellipse(img, (x2 - radius, y2 - radius), (radius, radius), 0, 0, 90, ellipse_color, ellipse_thickness)     # Bottom-right corner\n",
    "\n",
    "\n",
    "def draw_text_with_bg(frame, text, pos, font=cv.FONT_HERSHEY_SIMPLEX, font_scale=0.3, thickness=1, bg_color=(255, 255, 255),\n",
    "                      text_color=(0, 0, 0)):\n",
    "    \"\"\" Draws text with a background rectangle. \"\"\"\n",
    "    (text_width, text_height), baseline = cv.getTextSize(text, font, font_scale, thickness)\n",
    "    x, y = pos\n",
    "    cv.rectangle(frame, (x, y - text_height - baseline), (x + text_width, y + baseline), bg_color, cv.FILLED)\n",
    "    cv.putText(frame, text, (x, y), font, font_scale, text_color, thickness, lineType=cv.LINE_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Cascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting faces from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the face cascade\n",
    "face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_face(image_path, save_fig = False, filename = None):\n",
    "    # Read the image\n",
    "    img = cv.imread(image_path)\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    img_rgb_copy = img_rgb.copy()  # Copy the RGB image for original display\n",
    "\n",
    "    # Detect faces in the image\n",
    "    face_coords = face_cascade.detectMultiScale(img_gray, \n",
    "                                                scaleFactor=1.1,\n",
    "                                                minNeighbors=5,\n",
    "                                                minSize=(30, 30))\n",
    "\n",
    "    # Check if any faces were detected\n",
    "    if len(face_coords) > 0:\n",
    "        # Draw rectangles around detected faces\n",
    "        for (x, y, w, h) in face_coords:\n",
    "            cv.rectangle(img_rgb, (x, y), (x + w, y + h), (255, 0, 0), 4)\n",
    "            print(f\"Facial regions detected at ({x}, {y}, {x+w}, {y+h})\")\n",
    "    else:\n",
    "        print(\"Couldn't detect face in the image\")\n",
    "\n",
    "    # Plot the original image and the image with face detection (if any)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(img_rgb_copy)\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(img_rgb)\n",
    "    ax[1].set_title('Face Detected' if len(face_coords) > 0 else 'No Face Detected')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    if save_fig and filename:\n",
    "        file_path = os.path.join(\"DATA/IMAGES/detected_images\", filename)\n",
    "        fig.savefig(file_path, bbox_inches = 'tight', dpi = 200)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "img_file = \"DATA/IMAGES/raw_images/katherine.jpg\"\n",
    "detect_face(img_file, save_fig=True, filename= \"katherine_face.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_face('DATA/IMAGES/raw_images/sarapova.jpg', save_fig=True, filename=\"sarapova_face.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_face(\"DATA/IMAGES/raw_images/sarapova_1.jpg\", save_fig=True, filename=\"sarapova_face_1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_face(\"DATA/IMAGES/raw_images/sarapova_2.jpg\", save_fig=True, filename=\"sarapova_face_2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_face(\"DATA/IMAGES/raw_images/iskra.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing only the Largest Bounding Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address the issue of mistakenly detected regions that are not actual faces, we can filter the detected bounding boxes and only consider the largest one as the most likely facial region. This approach assumes that in an image where only one face is present (or even multiple), the largest bounding box is most likely to be the correct face detection, while smaller bounding boxes are more likely to be false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the face cascade\n",
    "face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_face(image_path, save_fig=False, filename=None):\n",
    "    # Read the image\n",
    "    img = cv.imread(image_path)\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    img_rgb_copy = img_rgb.copy()  # Copy the RGB image for original display\n",
    "\n",
    "    # Detect faces in the image\n",
    "    face_coords = face_cascade.detectMultiScale(img_gray, \n",
    "                                                scaleFactor=1.1,\n",
    "                                                minNeighbors=5,\n",
    "                                                minSize=(30, 30))\n",
    "\n",
    "    # Check if any faces were detected\n",
    "    if len(face_coords) > 0:\n",
    "        # Find the largest bounding box by area (width * height)\n",
    "        largest_face = max(face_coords, key=lambda rect: rect[2] * rect[3])\n",
    "        x, y, w, h = largest_face\n",
    "        cv.rectangle(img_rgb, (x, y), (x + w, y + h), (255, 255, 255), 6)\n",
    "        print(f\"Largest facial region detected at ({x}, {y}, {x+w}, {y+h})\")\n",
    "    else:\n",
    "        print(\"Couldn't detect face in the image\")\n",
    "\n",
    "    # Plot the original image and the image with face detection (if any)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(img_rgb_copy)\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(img_rgb)\n",
    "    ax[1].set_title('Face Detected' if len(face_coords) > 0 else 'No Face Detected')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    if save_fig and filename:\n",
    "        file_path = os.path.join(\"DATA/IMAGES/detected_images\", filename)\n",
    "        fig.savefig(file_path, bbox_inches='tight', dpi=200)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "img_file = \"DATA/IMAGES/raw_images/sarapova_2.jpg\"\n",
    "detect_face(img_file, save_fig=True, filename=\"sarapova_face_2_mod.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect faces from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_from_video(video_path, scale_factor, min_neighbors, resize_factor, save_video=False, filename=None):\n",
    "    \"\"\"\n",
    "    Detects faces in a video, filters them by checking for eyes, and optionally saves the output video.\n",
    "    \n",
    "    Parameters:\n",
    "        video_path (str or int): Path to the video file or 0 for webcam.\n",
    "        scale_factor (float): Parameter specifying the scaling factor for the face detection.\n",
    "        min_neighbors (int): Parameter specifying the number of neighbors for detecting faces.\n",
    "        resize_factor (float): Factor to resize the displayed video frames.\n",
    "        save_video (bool): If True, the video with detected faces is saved.\n",
    "        filename (str): The filename to save the processed video.\n",
    "    \"\"\"\n",
    "    # Load the face and eye cascade classifiers\n",
    "    face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    eye_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_eye.xml')\n",
    "    \n",
    "    # Open the video capture object (from file or webcam)\n",
    "    cap = cv.VideoCapture(0 if video_path == 0 else video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        raise Exception(\"Error: Unable to open the video file or webcam.\")\n",
    "    \n",
    "    # Get video properties (frame width, height, and FPS)\n",
    "    f_w, f_h = (int(cap.get(x)) for x in (cv.CAP_PROP_FRAME_WIDTH, cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv.CAP_PROP_FPS)) if video_path != 0 else 25\n",
    "\n",
    "    video_dir = \"DATA/VIDEOS/detected_videos\"\n",
    "    output = None\n",
    "    \n",
    "    # Prepare to save the output video if required\n",
    "    if save_video and filename:\n",
    "        os.makedirs(video_dir, exist_ok=True)\n",
    "        save_video_path = os.path.join(video_dir, filename)\n",
    "        fourcc = cv.VideoWriter_fourcc(*\"mp4v\")\n",
    "        output = cv.VideoWriter(save_video_path, fourcc, fps, (f_w, f_h))\n",
    "\n",
    "    try:\n",
    "        # Process the video frame by frame\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            # If no frame is returned, break the loop\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Convert the frame to grayscale for face detection\n",
    "            frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect faces in the grayscale frame\n",
    "            face_coords = face_cascade.detectMultiScale(image=frame_gray, \n",
    "                                                        scaleFactor=scale_factor, \n",
    "                                                        minNeighbors=min_neighbors)\n",
    "            \n",
    "            # If faces are detected, process each face\n",
    "            if len(face_coords) > 0:\n",
    "                face_count = 1\n",
    "                for (x, y, w, h) in face_coords:\n",
    "                    roi_gray = frame_gray[y:y+h, x:x+w]  # Region of interest for detecting eyes\n",
    "                    bbox = (x, y, x+w, y+h)\n",
    "\n",
    "                    # Detect eyes within the detected face\n",
    "                    eye_coords = eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "                    # Only consider regions with at least two detected eyes as valid faces\n",
    "                    if len(eye_coords) >= 2:\n",
    "                        # Draw a rounded rectangle around the face and add a label\n",
    "                        draw_rounded_rect(frame, bbox, ellipse_color=(0, 255, 0))\n",
    "                        label = f\"Face {face_count}\"\n",
    "                        draw_text_with_bg(frame, label, (x, y-10), font_scale=1, thickness=2, bg_color=(0, 0, 0), text_color=(0, 255, 0))\n",
    "                        face_count += 1\n",
    "\n",
    "            # If saving the video, write the frame with the detected faces\n",
    "            if save_video:\n",
    "                output.write(frame)\n",
    "\n",
    "            # Resize the frame for display\n",
    "            resized_frame = cv.resize(frame, (int(resize_factor * frame.shape[1]), int(resize_factor * frame.shape[0])))\n",
    "            cv.imshow('Video', resized_frame)\n",
    "\n",
    "            # Press 'p' to stop the video\n",
    "            if cv.waitKey(1) & 0xFF == ord('p'):\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during video processing: {str(e)}\")\n",
    "    finally:\n",
    "        # Release the resources properly\n",
    "        cap.release()\n",
    "        if save_video and output:\n",
    "            output.release()\n",
    "        cv.destroyAllWindows()\n",
    "        print(\"Video processing completed, resources released.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "video_path = \"https://videos.pexels.com/video-files/3209298/3209298-uhd_2560_1440_25fps.mp4\"\n",
    "file_name = \"face_detection_1.mp4\"\n",
    "\n",
    "detect_faces_from_video(video_path, 1.1, 5, 0.5, save_video=True, filename=file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face and eye detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_face_and_eye(image_path, save_fig=False, filename=None):\n",
    "    try:\n",
    "        # Load Haar cascades for eyes\n",
    "        eye_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_eye.xml')\n",
    "        if eye_cascade.empty():\n",
    "            raise Exception(\"Error loading eye cascade classifier!\")\n",
    "\n",
    "        # Load the image\n",
    "        img = cv.imread(image_path)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Could not load image at {image_path}\")\n",
    "\n",
    "        img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        img_rgb_copy = img_rgb.copy()\n",
    "        thickness = max(1, int(img.shape[1] / 200)) \n",
    "\n",
    "        # Load face cascade and detect faces\n",
    "        face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        if face_cascade.empty():\n",
    "            raise Exception(\"Error loading face cascade classifier!\")\n",
    "\n",
    "        face_coords = face_cascade.detectMultiScale(img_gray, \n",
    "                                                    scaleFactor=1.1,\n",
    "                                                    minNeighbors=5,\n",
    "                                                    minSize=(30, 30))\n",
    "\n",
    "        print(f\"Number of facial regions detected is {len(face_coords)}\")\n",
    "        \n",
    "        if len(face_coords) > 0:\n",
    "            count_face = 1\n",
    "            for (x, y, w, h) in face_coords:\n",
    "                try:\n",
    "                    print(f\"\\nFacial region {count_face} detected at ({x}, {y}, {x+w}, {y+h})\")\n",
    "                    bbox = (x, y, x+w, y+h)\n",
    "\n",
    "                    # Eyes detection within the facial region\n",
    "                    roi_gray = img_gray[y:y+h, x:x+w]\n",
    "                    roi_color = img_rgb[y:y+h, x:x+w]\n",
    "\n",
    "                    eyes_coords = eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "                    print(f\"\\nNumber of eye features detected in this region is {len(eyes_coords)}\")\n",
    "\n",
    "                    if len(eyes_coords) >= 2:\n",
    "                        count_eyes = 1\n",
    "                        for (ex, ey, ew, eh) in eyes_coords:\n",
    "                            draw_rounded_rect(img_rgb, bbox, ellipse_color=(204, 0, 102), line_thickness=thickness,\n",
    "                                              ellipse_thickness=thickness+2, radius=35)\n",
    "                            cv.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (102, 0, 204), thickness)\n",
    "                            print(f\"Eye features {count_eyes} detected at ({ex}, {ey}, {ex+ew}, {ey+eh}) for facial region {count_face} at ({x}, {y}, {x+w}, {y+h})\")\n",
    "                            count_eyes += 1\n",
    "                    else:\n",
    "                        print(f\"Couldn't detect eyes in facial region {count_face} at ({x}, {y}, {x+w}, {y+h})\")\n",
    "\n",
    "                    count_face += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing facial region {count_face}: {e}\")\n",
    "\n",
    "        else:\n",
    "            image_name = image_path.split('\\\\')[-1]\n",
    "            print(f\"Couldn't detect face for the {image_name}\")\n",
    "\n",
    "        # Plot the original image and the image with face detection (if any)\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax[0].imshow(img_rgb_copy)\n",
    "        ax[0].set_title('Original Image')\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].imshow(img_rgb)\n",
    "        ax[1].set_title('Face and Eyes detected' if len(face_coords) > 0 else 'No Face Detected')\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        if save_fig and filename:\n",
    "            try:\n",
    "                # Ensure the folder exists\n",
    "                save_dir = \"DATA/IMAGES/detected_images\"\n",
    "                if not os.path.exists(save_dir):\n",
    "                    os.makedirs(save_dir)\n",
    "                    \n",
    "                filepath = os.path.join(save_dir, filename)\n",
    "                fig.savefig(filepath, bbox_inches='tight', dpi=200)\n",
    "                print(f\"Saved image with detections to {filepath}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving file: {e}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        print(f\"File not found: {fnf_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Call the function\n",
    "detect_face_and_eye(\"DATA/IMAGES/raw_images/katherine.jpg\", save_fig=True, filename=\"katherine_eye.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_face_and_eye(\"DATA/IMAGES/raw_images/sarapova_1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_face_and_eye(\"DATA/IMAGES/raw_images/ronaldo.jpg\", save_fig=True, filename=\"ronaldo_eyes.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_face_and_eye(\"DATA/IMAGES/raw_images/elon.jpg\", save_fig=True, filename=\"elon_eyes.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_face_and_eye(\"DATA/IMAGES/raw_images/virat_1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_face_and_eye(\"DATA/IMAGES/raw_images/group_selfie.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempting to draw the bounding boxes only the eyes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure we're only detecting and drawing bounding boxes for the eyes (instead of other facial regions like lips or eyebrows), we can filter the detected eye regions by their relative vertical positions. Specifically, if the centers of two detected eye bounding boxes lie within a specified vertical limit (e.g., ±50 pixels), we can confirm that they are likely eyes.\n",
    "\n",
    "Here are the steps that were followed to achieve this:\n",
    "\n",
    "**Approach**:\n",
    "1. After detecting all eye regions within the face (eyes_coords), calculate the centers of the bounding boxes for the detected eyes.\n",
    "\n",
    "2. Compare the vertical positions of the centers of each pair of detected eye bounding boxes. If the difference in their vertical positions is within a set range (e.g., ±20 pixels), assume these are valid eye detections.\n",
    "3. Draw bounding boxes for only those pairs of eye regions that meet this condition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_and_eye_1(image_path, save_fig=False, filename=None):\n",
    "    try:\n",
    "        # Load Haar cascade for eyes\n",
    "        eye_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_eye.xml')\n",
    "        if eye_cascade.empty():\n",
    "            raise Exception(\"Error loading eye cascade classifier!\")\n",
    "\n",
    "        # Load the image\n",
    "        img = cv.imread(image_path)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Could not load image at {image_path}\")\n",
    "\n",
    "        img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        img_rgb_copy = img_rgb.copy()\n",
    "        thickness = max(1, int(img.shape[1] / 200)) \n",
    "\n",
    "        # Define vertical limit for eye alignment\n",
    "        vertical_limit = 50  # Change this as per the image\n",
    "\n",
    "        # Load face cascade and detect faces\n",
    "        face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        if face_cascade.empty():\n",
    "            raise Exception(\"Error loading face cascade classifier!\")\n",
    "\n",
    "        face_coords = face_cascade.detectMultiScale(img_gray, \n",
    "                                                    scaleFactor=1.1,\n",
    "                                                    minNeighbors=5,\n",
    "                                                    minSize=(30, 30))\n",
    "\n",
    "        print(f\"Number of facial regions detected is {len(face_coords)}\")\n",
    "        \n",
    "        if len(face_coords) > 0:\n",
    "            count_face = 1\n",
    "            for (x, y, w, h) in face_coords:\n",
    "                try:\n",
    "                    print(f\"\\nFacial region {count_face} detected at ({x}, {y}, {x+w}, {y+h})\")\n",
    "                    bbox = (x, y, x+w, y+h)\n",
    "\n",
    "                    # Eyes detection within the facial region\n",
    "                    roi_gray = img_gray[y:y+h, x:x+w]\n",
    "                    roi_color = img_rgb[y:y+h, x:x+w]\n",
    "\n",
    "                    eyes_coords = eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "                    print(f\"\\nNumber of eye features detected in this region is {len(eyes_coords)}\")\n",
    "\n",
    "                    valid_eye_pairs = []\n",
    "\n",
    "                    # Only consider valid eye pairs based on their vertical alignment\n",
    "                    if len(eyes_coords) >= 2:\n",
    "                        eye_centers = [(ex + ew // 2, ey + eh // 2, (ex, ey, ew, eh)) for (ex, ey, ew, eh) in eyes_coords]\n",
    "\n",
    "                        # Check pairwise combinations of eye bounding boxes\n",
    "                        for i in range(len(eye_centers)):\n",
    "                            for j in range(i+1, len(eye_centers)):\n",
    "                                _, eye_i_y, eye_i_box = eye_centers[i]\n",
    "                                _, eye_j_y, eye_j_box = eye_centers[j]\n",
    "\n",
    "                                if abs(eye_i_y - eye_j_y) <= vertical_limit:\n",
    "                                    # If the vertical difference is within the limit, consider as a valid pair\n",
    "                                    valid_eye_pairs.append(eye_i_box)\n",
    "                                    valid_eye_pairs.append(eye_j_box)\n",
    "\n",
    "                        # Remove duplicates and draw bounding boxes for valid eye regions\n",
    "                        valid_eye_pairs = list(set(valid_eye_pairs))\n",
    "\n",
    "                        if valid_eye_pairs:\n",
    "                            for count_eyes, (ex, ey, ew, eh) in enumerate(valid_eye_pairs, 1):\n",
    "                                draw_rounded_rect(img_rgb, bbox, ellipse_color=(204, 0, 102),line_thickness=thickness, ellipse_thickness=thickness+2,  radius=35)\n",
    "                                cv.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (102, 0, 204), thickness)\n",
    "                                print(f\"Eye features {count_eyes} detected at ({ex}, {ey}, {ex+ew}, {ey+eh}) for facial region {count_face} at ({x}, {y}, {x+w}, {y+h})\")\n",
    "                        else:\n",
    "                            print(f\"No valid eye pairs detected in facial region {count_face}.\")\n",
    "                    else:\n",
    "                        print(f\"Couldn't detect enough eyes in facial region {count_face} at ({x}, {y}, {x+w}, {y+h})\")\n",
    "\n",
    "                    count_face += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing facial region {count_face}: {e}\")\n",
    "\n",
    "        else:\n",
    "            image_name = image_path.split('\\\\')[-1]\n",
    "            print(f\"Couldn't detect face for the {image_name}\")\n",
    "\n",
    "        # Plot the original image and the image with face detection (if any)\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax[0].imshow(img_rgb_copy)\n",
    "        ax[0].set_title('Original Image')\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].imshow(img_rgb)\n",
    "        ax[1].set_title('Face and Eyes detected' if len(face_coords) > 0 else 'No Face Detected')\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        if save_fig and filename:\n",
    "            try:\n",
    "                # Ensure the folder exists\n",
    "                save_dir = \"DATA/IMAGES/detected_images\"\n",
    "                if not os.path.exists(save_dir):\n",
    "                    os.makedirs(save_dir)\n",
    "                    \n",
    "                filepath = os.path.join(save_dir, filename)\n",
    "                fig.savefig(filepath, bbox_inches='tight', dpi=200)\n",
    "                print(f\"Saved image with detections to {filepath}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving file: {e}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        print(f\"File not found: {fnf_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Call the function\n",
    "detect_face_and_eye_1(\"DATA/IMAGES/raw_images/katherine.jpg\", save_fig=True, filename=\"katherine_eye_1.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_face_and_eye(\"DATA/IMAGES/raw_images/sarapova_1.jpg\")\n",
    "detect_face_and_eye_1(\"DATA/IMAGES/raw_images/sarapova_1.jpg\", save_fig=True, filename=\"sarapova_eyes.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human full body detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Body Detection from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_human_body(image_path, scale_factor, min_neighbours, save_fig=False, filename=None):\n",
    "    try:\n",
    "        # Correct path to the full-body Haar cascade\n",
    "        fullbody_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_fullbody.xml')\n",
    "        if fullbody_cascade.empty():\n",
    "            raise Exception(\"Error loading full body cascade classifier!\")\n",
    "\n",
    "        # Handle image input (URL or local path)\n",
    "        if image_path.startswith(('https', 'http')):\n",
    "            try:\n",
    "                response = requests.get(image_path)\n",
    "                if response.status_code != 200 or not response.content:\n",
    "                    raise Exception(f\"Failed to fetch image from the web. Status code: {response.status_code}\")\n",
    "                \n",
    "                # Convert response content to image\n",
    "                image_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "                img = cv.imdecode(image_array, cv.IMREAD_COLOR)\n",
    "                if img is None:\n",
    "                    raise Exception(\"Error decoding the image from URL.\")\n",
    "            except requests.exceptions.RequestException as req_err:\n",
    "                print(f\"Error fetching image: {req_err}\")\n",
    "                return\n",
    "        else:\n",
    "            img = cv.imread(image_path)\n",
    "            if img is None:\n",
    "                raise FileNotFoundError(f\"Failed to load image from local path: {image_path}\")\n",
    "        \n",
    "        # Convert image to RGB and grayscale\n",
    "        img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        img_rgb_copy = img_rgb.copy()\n",
    "        thickness = max(1, int(img.shape[1] / 200))\n",
    "\n",
    "        # Detect human bodies\n",
    "        body_coords = fullbody_cascade.detectMultiScale(img_gray, \n",
    "                                                        scaleFactor=scale_factor,\n",
    "                                                        minNeighbors=min_neighbours)\n",
    "\n",
    "        print(f\"Number of bodies detected: {len(body_coords)}\")\n",
    "\n",
    "        if len(body_coords) > 0:\n",
    "            body_count = 1\n",
    "            for (bx, by, bw, bh) in body_coords:\n",
    "                try:\n",
    "                    # Draw rectangles and labels\n",
    "                    cv.rectangle(img_rgb, (bx, by), (bx + bw, by + bh), (255, 255, 255), thickness)\n",
    "                    label = f\"Body {body_count}\"\n",
    "                    draw_text_with_bg(img_rgb, label, (bx, by - 10), font_scale=2, thickness=3)\n",
    "                    print(f\"Body {body_count} detected at ({bx}, {by}, {bx + bw}, {by + bh})\")\n",
    "                    body_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing body {body_count}: {e}\")\n",
    "        else:\n",
    "            print(\"No bodies detected.\")\n",
    "\n",
    "        # Plot the original and detected images\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax[0].imshow(img_rgb_copy)\n",
    "        ax[0].set_title('Original Image')\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].imshow(img_rgb)\n",
    "        ax[1].set_title(f'Bodies Detected: {len(body_coords)}' if len(body_coords) > 0 else 'No Bodies Detected')\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        if save_fig and filename:\n",
    "            try:\n",
    "                # Ensure the folder exists\n",
    "                save_dir = \"DATA/IMAGES/detected_images\"\n",
    "                if not os.path.exists(save_dir):\n",
    "                    os.makedirs(save_dir)\n",
    "\n",
    "                filepath = os.path.join(save_dir, filename)\n",
    "                fig.savefig(filepath, bbox_inches='tight', dpi=200)\n",
    "                print(f\"Saved image with detections to {filepath}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving file: {e}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        print(f\"File not found: {fnf_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Call the function\n",
    "detect_human_body(\"https://images.pexels.com/photos/28957602/pexels-photo-28957602/free-photo-of-busy-urban-street-scene-in-glasgow-city-center.jpeg\",\n",
    "                  1.1, 3, save_fig=True, filename=\"body_detection.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_human_body(\"DATA/IMAGES/raw_images/people_on_streets_2.jpg\" , 1.1, 5, save_fig=True, filename='body_detection_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_human_body(\"DATA/IMAGES/raw_images/people_on_streets.jpg\", 1.05, 3, save_fig=True, filename='body_detection_2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Body detection from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_human_body_from_video(video_path, scale_factor, min_neighbors, resize_factor, save_video=False, filename=None):\n",
    "    try:\n",
    "        # Load full-body Haar cascade\n",
    "        fullbody_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_fullbody.xml')\n",
    "        if fullbody_cascade.empty():\n",
    "            raise Exception(\"Error loading full-body cascade classifier!\")\n",
    "\n",
    "        # Open the video file\n",
    "        cap = cv.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise FileNotFoundError(f\"Error: Couldn't open the video at {video_path}!\")\n",
    "\n",
    "        # Get video properties: width, height, and FPS\n",
    "        f_w, f_h, fps = (int(cap.get(x)) for x in (cv.CAP_PROP_FRAME_WIDTH, cv.CAP_PROP_FRAME_HEIGHT, cv.CAP_PROP_FPS))\n",
    "\n",
    "        video_dir = \"DATA/VIDEOS/detected_videos\"\n",
    "        output = None\n",
    "\n",
    "        # Prepare to save video if requested\n",
    "        if save_video and filename:\n",
    "            try:\n",
    "                if not os.path.exists(video_dir):\n",
    "                    os.makedirs(video_dir)  # Ensure the save directory exists\n",
    "\n",
    "                save_video_path = os.path.join(video_dir, filename)\n",
    "                fourcc = cv.VideoWriter_fourcc(*\"mp4v\")\n",
    "                output = cv.VideoWriter(save_video_path, fourcc, fps, (f_w, f_h))\n",
    "            except Exception as e:\n",
    "                print(f\"Error preparing video writer: {e}\")\n",
    "                raise\n",
    "\n",
    "        # Process video frames\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"End of video stream or error reading frame.\")\n",
    "                break\n",
    "\n",
    "            # Convert frame to grayscale\n",
    "            frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect human bodies in the current frame\n",
    "            body_coords = fullbody_cascade.detectMultiScale(frame_gray, scaleFactor=scale_factor, minNeighbors=min_neighbors)\n",
    "\n",
    "            if len(body_coords) > 0:\n",
    "                body_count = 1\n",
    "                for (x, y, w, h) in body_coords:\n",
    "                    try:\n",
    "                        # Draw rectangle around detected bodies\n",
    "                        cv.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 255), 4)\n",
    "                        label = f\"Body_{body_count}\"\n",
    "                        draw_text_with_bg(frame, label, (x, y - 10), font_scale=0.75, thickness=2)\n",
    "                        body_count += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing body {body_count}: {e}\")\n",
    "\n",
    "            # Write the processed frame to the output video\n",
    "            if save_video and output:\n",
    "                output.write(frame)\n",
    "\n",
    "            # Resize the frame for display\n",
    "            resized_frame = cv.resize(frame, (int(resize_factor * frame.shape[1]), int(resize_factor * frame.shape[0])))\n",
    "            cv.imshow('Video', resized_frame)\n",
    "\n",
    "            # Break if the 'p' key is pressed\n",
    "            if cv.waitKey(1) & 0xFF == ord('p'):\n",
    "                print(\"Video paused/stopped by user.\")\n",
    "                break\n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        print(fnf_error)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        # Release video capture and writer resources\n",
    "        if cap:\n",
    "            cap.release()\n",
    "        if save_video and output:\n",
    "            output.release()\n",
    "        cv.destroyAllWindows()\n",
    "        print(\"Video processing complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_human_body_from_video(\"https://videos.pexels.com/video-files/1596860/1596860-sd_640_360_30fps.mp4\",\n",
    "                             1.1, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_human_body_from_video(\"https://videos.pexels.com/video-files/855789/855789-hd_1920_1080_30fps.mp4\",\n",
    "                             1.1, 3, 0.5, save_video=True, filename='body_detection_vid.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
